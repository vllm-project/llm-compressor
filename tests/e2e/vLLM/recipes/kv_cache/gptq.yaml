quant_stage:
  quant_modifiers:
    GPTQModifier:
      sequential_update: false
      ignore: ["lm_head"]
      config_groups:
          group_0:
              weights:
                  num_bits: 4
                  type: "int"
                  symmetric: true
                  strategy: "channel"
                  actorder: False
              targets: ["Linear"]
      kv_cache_scheme:
        {num_bits: 8, type: float, symmetric: true, strategy: tensor}