cadence: "nightly"
test_type: "regression"
model: TinyLlama/TinyLlama-1.1B-Chat-v1.0
recipe: tests/e2e/vLLM/recipes/non_uniform/recipe_gptq_awq.yaml
dataset_id: HuggingFaceH4/ultrachat_200k
dataset_split: train_sft
scheme: gptq_awq_mixed
save_dir: TinyLlama-1.1B-Chat-v1.0-gptq-awq-mixed
num_calibration_samples: 256
